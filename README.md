# üìä Modelo Preditivo de Diabetes com Decision Tree e Random Forest (SHAP)

Trabalho de entrega da Fase 1 da P√≥s Gradua√ß√£o IA para Devs da FIAP

---

## üéØ Objetivo
Desenvolver e avaliar modelos de **aprendizado de m√°quina supervisionado** para **aux√≠lio ao diagn√≥stico de diabetes**, comparando os algoritmos **Decision Tree** e **Random Forest**, com an√°lise detalhada de desempenho e **explicabilidade via SHAP**.

> ‚ö†Ô∏è O modelo n√£o substitui diagn√≥stico m√©dico. Atua como ferramenta de **apoio √† decis√£o**.

---

## üìÇ Dataset
- **Nome:** Pima Indians Diabetes Database
- **Fonte:** Kaggle
- **Link:** https://www.kaggle.com/datasets/mathchi/diabetes-data-set/data
- **Descri√ß√£o:** Dados cl√≠nicos e demogr√°ficos utilizados para prever a presen√ßa de diabetes (Outcome).

Observa√ß√£o importante:
- O dataset **n√£o possui valores NaN expl√≠citos**.
- Algumas vari√°veis cl√≠nicas utilizam **zero como valor inv√°lido**, tratado adequadamente no pr√©-processamento.

---

## üß™ Metodologia

### 1. An√°lise Explorat√≥ria
- Verifica√ß√£o de valores ausentes (NaN)
- An√°lise de distribui√ß√£o das classes (desbalanceamento)
- Avalia√ß√£o explorat√≥ria de outliers

### 2. Pr√©-processamento
- Substitui√ß√£o de zeros inv√°lidos pela **mediana** (Glucose, BloodPressure, SkinThickness, Insulin, BMI)
- N√£o foi aplicada normaliza√ß√£o, pois **Decision Tree e Random Forest n√£o dependem de escala**

### 3. Modelagem
- **Decision Tree Classifier**
- **Random Forest Classifier**

Motiva√ß√£o:
- Modelos baseados em √°rvores oferecem **boa performance** e **alta interpretabilidade**, especialmente relevantes em contextos de sa√∫de.

### 4. Treinamento e Valida√ß√£o
- Divis√£o dos dados:
  - 80% treino
  - 20% teste
- Amostragem estratificada para preserva√ß√£o da propor√ß√£o das classes

### 5. Avalia√ß√£o de Desempenho
- Accuracy
- Precision
- Recall
- F1-score
- Curva ROC
- Matrizes de confus√£o (tabelas e heatmaps)

### 6. Ajuste de Hiperpar√¢metros
- Random Forest otimizado com **RandomizedSearchCV**

### 7. Explicabilidade (SHAP)
- Utiliza√ß√£o do **TreeExplainer**
- An√°lise da contribui√ß√£o individual das features
- Visualiza√ß√£o global com **SHAP summary plot**

### 8. An√°lises Complementares
- Import√¢ncia das features (Random Forest)
- Correla√ß√£o entre cada feature e o Outcome
- Identifica√ß√£o dos principais fatores de risco

---

## üìà Principais Resultados
- O **Random Forest apresentou melhor desempenho geral**, superando a Decision Tree em acur√°cia e estabilidade.
- As features mais relevantes para a predi√ß√£o incluem vari√°veis cl√≠nicas como **Glucose**, **BMI** e **Age**.
- A an√°lise SHAP confirmou a coer√™ncia cl√≠nica das decis√µes do modelo.

---

## üìå Estrutura do Notebook
- An√°lise de valores ausentes (NaN)
- Tratamento de dados inv√°lidos
- Modelagem e compara√ß√£o de algoritmos
- Relat√≥rios de classifica√ß√£o (texto + gr√°ficos)
- Matrizes de confus√£o (tabelas + heatmaps)
- Curvas ROC
- Import√¢ncia das features
- SHAP e interpretabilidade
- An√°lise de correla√ß√£o com Outcome

---

## üõ†Ô∏è Tecnologias Utilizadas
- Python
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- SHAP

---




